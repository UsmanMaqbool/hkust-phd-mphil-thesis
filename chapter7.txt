\chapter{MAQBOOL}
\label{sec-pslen}

\section{Introduction}

\label{sec.introduction}
Image retrieval has extensive usage in the robotics industry with application in visual place recognition (VPR)\cite{Panphattarasap2017, Sunderhauf2015}, loop closure detection \cite{Sarlin2018, Gawel2018} and 3D mapping \cite{bhutta2020loopbox,Bhutta2018}. The standard baseline for image retrieval uses the vocabulary building and feature matching of a query image with database images \cite{fabmap, cummins2011appearance, hou2018bocnf}. Several feature estimation techniques have been proposed, such as speeded up robust features (SURF), scale-invariant feature transform (SIFT), and vector of locally aggregated descriptors (VLAD) \cite{jegou2010aggregating} to determine the image correspondence. Based on the features, different approaches are introduced to meet challenging scenarios, such as seasonal changes \cite{Hausler2019, Liu2019a}, lightweight descriptor matching\cite{Khaliq2018}, region-wise feature comparison \cite{chen2017only, Khaliq2019CAMAL}, scene changes by the renovation or modification of buildings \cite{Torii2018}, following the repetitive structures \cite{Torii2015} \cite{Chen2011} and memorable-maps-based methods \cite{zaffar2018memorable}. \\

Integrating the 3D-depth information and the corresponding 2-D images also enhances the system performance in loop closure detection \cite{Sarlin2018, Gawel2018, bernreiter2019multiple,taira2018inloc}.
Moreover, GPS information \cite{pillai2019self} and attention-seeking approaches \cite{xin2019localizing, Chen2017, Pal2019} have also shown better results for the image retrieval tasks. Authors also proposed the recombination of images to find the nearest matches in the database. Works related to landmarks distribution and partitioning pictures based on regions are also present in the literature \cite{Panphattarasap2017, Sunderhauf2015}. Moreover, early visual features filtration helps in improving network-based place recognition \cite{Hausler2019}. In this approach, a feature vector is extracted from a viewpoint-invariant layer to match later images. \\

Convolutional neural network (CNN)-based approaches such as NetVLAD \cite{arandjelovic2016netvlad} and DGC-Net \cite{melekhov2019dgc} produce promising results on challenging datasets such as the 247 Tokyo dataset\cite{Torii2018}, Tokyo Time Machine, and Pittsburgh dataset\cite{Torii2015}. For large-scale image correspondence matching, scientists have also introduced several upgrades to the network. HD-CNN \cite{Yan2015} presented a hierarchical deep CNN scheme. Similarly, partitioning the spatial information in higher layers is done by \cite{Yu2019SpatialRecognition} and \cite{camara2019spatio}. \\

\cite{Zhai} incorporates NetVLAD and makes a pyramid of the features to achieve better results. Despite the better real-time performance of DGC-Net \cite{melekhov2019dgc}, sometimes, the system faces difficulty due to the incorporation of time-changing objects in the images. \cite{Chen2017} introduces a multi-layered region-based method that extends DGC-Net and incorporates the NetVLAD. A multi-layered region-based framework is introduced in \cite{laskar2020geometric}, which also uses NetVLAD and performs dense pixel matching to achieve better place recognition. But the utilization of these methods in a real-time system is still very challenging.\\

\begin{figure}[!t] 
	\centering
		\includegraphics[width=.98\linewidth]{maqbool/images/tokyo-heat_map-bar.jpg}
		
	\raggedright	
	\captionsetup[subfigure]{width=.46\linewidth}
	\subfloat[Top-ranked image correspondence proposals are marked on the query image.] {\label{fig:first-1} 
		\includegraphics[width=.46\linewidth]{maqbool/images/fig2-tokyo-boxed-bold.jpg}
	}
	\captionsetup[subfigure]{width=.46\linewidth}
	\subfloat[Proposals are mapped to the spatial information of pre-$\ell_2$ layer of NetVLAD] {\label{fig:first-2}
		\includegraphics[width=.46\linewidth]{maqbool/images/fig2-tokyo-heat_map-1Q-grey-boxed.jpg}
	}
	\caption{Query image from the 247 Tokyo dataset. Top region proposals are selected using Edge Boxes \cite{Zitnick2014}. The intensity bar shows the top scoreing region selections on the image.}
	\label{fig:first} 
\end{figure}
\subsection{Motivation}
All the above-described approaches require re-training the complex networks for enhancing system accuracy. In addition, it involves high-level intensive computation to address a particular kind of problem. Instead of going deep enough by following a large training pipeline, we probabilistically enhance the image retrieval performance based on the pre-trained model for more reliable place recognition. We introduce the Multiple AcQuisitions of perceptiBle regiOns for priOr Learning (MAQBOOL) approach. Image retrieval using our system performs better than the schemes introduced by changing the network with complex structure and adding additional sensors information or repetitive training to get impressive results on challenging datasets.\\

Fig \ref{fig:first} shows the main idea of our work. Fig. \ref{fig:first-1} shows the real image with several marked boxes of different regions based on their respective scores, and Fig. \ref{fig:first-2} shows the same areas marked in the spatial layer. These marked correspondence regions will help in the probabilistic landmarks elevation. We split the full spatial information into multiple regions and estimate their $\ell_2$ distance co-relations, which significantly increases the power of pre-trained models.\\


%$$

\section{Multiple acquisitions of perceptible regions for prior learning}
\label{sec.framworkwork}
An overview of our MAQBOOL system is shown in Fig. \ref{figure-main}. Our contributions are related to the bottom part of the shown framework. Given a query image, we retrieve the nearest candidates in the database descriptor space. We use NetVLAD, which is a fast and scalable method, for the image retrieval application. 

Our proposed method consists of three parts. Part I explains the selection of the top regions for the local representation from the images. Part II describes the corresponding spatial information processing using NetVLAD. Part III shows the probabilistic manipulation in a pairwise manner of the query image with initially retrieved database images for more reliable place recognition. These three parts are explained in the following subsections.

\subsection{Top Regions Selection}
In Section \ref{sec.relatedwork}, we explained that APANET \cite{zhu2018attention} uses the top regions and applies single and cascaded blocks to achieve better performance. Instead, using the regions section methods in \cite{xiao2015application-47} and \cite{yan2017fine-48}, we use fast and unsupervised approach Edge Boxes \cite{Zitnick2014}. It is an unsupervised method that detects the likelihood of an object based on the points on the edges, also explained in Section \ref{sec-edges-box}. We choose the top 50 proposals based on the objectness score obtained by the Edge boxes. 

\subsection{Spatial Landmarks Estimation }
We process the landmarks information at the pre-$\ell_2$ layer of NetvLAD. All the top regions' enclosed boxes are mapped to this pre-$\ell_2$ layer. We crop the corresponding spatial information to create the NetVLAD features vectors of 512-D and 4096-D of all the boxes. These feature vectors will be used for the probabilistic landmarks elevation in the next section.
Fig. \ref{fig:first} shows the top proposals based on the objectness scores and their mapping at the pre-$\ell_2$ layer of the NetVLAD pipeline.

\subsection{Probabilistic Spatial Landmarks Elevation}
For a query image $I_q$, NetVLAD can predict the top-100 matches from the database, based on the $\ell_2$ distances in the descriptor space. Let's assume, for this query image $I_q$, $I_{id}$ are the images from the database and $d_{id}$ are their corresponding $\ell_2$ distances, where ${id} \in \{1,2,3,..., 100\}$.

For the feature vector 512-D and number of spatial regions 50, we define the whole image representation by \textbf{F}, which has a size of $ 50 \times 512 $.

Instead of making the system complicated by incorporating multi-scale pyramid aggregation or estimating sets of cyclically consistent dense pixel matches. We simply performed probabilistic spatial landmarks elevation followed by the correlation distance for the re-ranking of the top retrieved candidates. 

We estiamte the correlation distance matrix $\textbf{C}_{n \times n}$ of the query image $\textbf{F}_q$ with the $j^{th}$ database images $\textbf{F}_{db}^j$ as

$$ 
\textbf{C}_{n \times n}^j = \textbf{F}_{q(n \times d)}^j 
\times \textbf{F}^j_{db(n \times d)}
$$
where n is the number of boxes and d is the feature dimension. 

We first filter the irrelevant distances score by subtracting the maximum distance $d_{pre} = \{d_1, d_2, .....,d_{100}\}$ , which are in ascending order:

$$  \textbf{C}_{f} =  \textbf{C}_{n \times n} - d_{max}.$$
We further improve the distance matrix by neglecting the maximum distances:
$$
\textbf{D}^{j} = 
\begin{cases}
\textbf{C}_{f}^j \odot sgn(\textbf{C}^j), & \text{for } c_{f} < 0 \\
0, & \text{for } c_{f} \geq 0, \\
\end{cases}
$$
where $ \textbf{D}^{j} $ is the original distance of the query from the $ j^{th} $ database's predicted images.


$$ \textbf{C}_{q(n \times n)}^j = \textbf{C}_{q(n \times n)}^j \odot |\textbf{D}_{qj}^j|$$


We estimate the probability $P^j$  by utilizing the correlation distance matrix of the query image to the $j^{th}$ database image. It can be calculated as 

$$
P^j = \underbrace{\frac{e^{-d_{pre}}}{ \sum_i e^{-d_{pre}^i}}}_\text{softmax}.e^{-c_{min}}
$$
where $c_{min}$ is the minimum value of $\textbf{C}_{q(n \times n)^j}$. We further determine the information $\textbf{S}_{xy}^j$ based on the size of the boxes of both the query and database image:


%abs(D_diff+exp(-1.*D_diff_predict));



$$
s_{xy}^j = \beta* P_b^q* P_b^{db} * e^{-(d_{pre}^j+c_{xy})} * e^{R^\prime},
$$
\\
where  $x,y \in \{1,...n\}$,  $s_{xy}^j \in \textbf{S}_{xy}^j$, $R^\prime = \frac{d}{dx}(d_{pre}^j)$, 
$$
P_b^q = e^{-\frac{b_w^q*b_h^q}{Q_w*Q_h} } \text{ and } P_b^{db} = e^{-\frac{b_w^{db}*b_h^{db}}{DB_w*DB_h} }
$$

$$
\textbf{M}_{q}^j =  \textbf{S}_{xy}^j \odot \textbf{C}_{q(n \times n)}^j. \\
$$
We pass this estimated information to the regression process to create the predictive model.

\subsection{Prediction Model and Probabilistic Distance Update}

We design the probabilistic decision layer (PDL) using the ground truth based on the ToktoTM validation dataset. The information estimated in the previous subsection is used in the creating the model as follows:

$$ P_M^j =  f(\textbf{M}, d_{pre}, \textbf{C}_{qdb}). $$

After creating the model, we apply it to work as the prior distribution to predict the response. In this manner, we update all the distances of the top candidates for re-ranking the retrieval images as follows:
$$
d_{new}^j = d_{pre}^j+\alpha e^{(-P_M^j)}, P_M^j \in [1,2]
$$ 

We keep the model response binary. The predicted value '1' corresponds to the irrelevant match, whereas '2' tells us about the nearest match.


\section{Results and Discussion}
\label{sec.results}


\subsection{Datasets and Implementation}
For performance evaluation, we tested our MAQBOOL method on the Pittsburgh \cite{Torii2015} and Tokyo 247 \cite{Torii2018} datasets. The Pittsburgh dataset consists of 254K perspective images taken from 10.6k Google Street View and 8.2K query images, while Tokyo 247 dataset has 76k database images and 315 query images. We used the same model, generated using VGG-16 followed by NetVLAD, on these datasets.
%
%\begin{figure}[!t]
%	\centering
%
%	\begin{subfigure}[pt]{0.24\textwidth}
%		\resizebox{\columnwidth}{!}{
%			\begin{tikzpicture}%[width = 1in, height = 4in]
%				\begin{axis}
%					[curve plot style]
%
%					\addplot [color=blue, mark=square]
%					table {data/vd16_pitts30k_to_tokyo247_maqbool_D_512.dat};
%					\addplot [color=green, mark=square]
%					table {data/vd16_pitts30k_to_tokyo247_maqbool_R_512.dat};
%
%					\addplot [color=black, mark=asterisk]
%					table {data/vd16_pitts30k_to_tokyo247_netvlad_512.dat};
%
%					\legend{MAQBOOL$_{DT-50}$(ours), MAQBOOL$_{DT-100}$(ours),NetvLAD(V)+white}
%				\end{axis}
%			\end{tikzpicture}
%		}
%		\captionsetup{width=.9\linewidth}
%		\caption{Recall test on Tokyo 247 at 512-D}
%		\label{fig:pitts2tokyo-512}
%		\label{fig:sub1}
%	\end{subfigure}
%	\begin{subfigure}[pt]{0.24\textwidth}
%		\resizebox{\columnwidth}{!}{
%			\pgfplotsset{ymax=90, ymin= 64}
%			\begin{tikzpicture}%[width = 1in, height = 4in]
%				\begin{axis}
%					[curve plot style]
%
%					\addplot [color=blue, mark=square]
%					table {data/vd16_pitts30k_to_tokyo247_maqbool_D_4096.dat};
%					\addplot [color=green, mark=square]
%					table {data/vd16_pitts30k_to_tokyo247_maqbool_R_4096.dat};
%					\addplot [color=black, mark=asterisk]
%					table {data/vd16_pitts30k_to_tokyo247_netvlad_4096.dat};
%					\legend{MAQBOOL$_{DT-50}$(ours), MAQBOOL$_{DT-100}$(ours),NetvLAD(V)+white}
%				\end{axis}
%			\end{tikzpicture}
%		}
%		\captionsetup{width=.9\linewidth}
%		\caption{Recall test on Tokyo 247 at 4096-D}
%		\label{fig:pitts2tokyo-4096}
%	\end{subfigure}
%	\caption{MAQBOOL performance comparison with NetVLAD on Tokyo 247 dataset. Their retrieval performances are evaluated using the same VGG model, which is trained on the Pitts250k dataset.}
%	\label{fig:pitts2tokyo}
%\end{figure}

\begin{figure}[!t] 
	\centering
	\raggedright	
	\captionsetup[subfigure]{width=.85\linewidth}
	\subfloat[Recall test on Tokyo 247 at 512-D] 
	{	\label{fig:pitts2tokyo-512} 
		\resizebox{.46\linewidth}{!}{
			\begin{tikzpicture}[trim axis left]%[width = 1in, height = 4in]
			\begin{axis}
			[curve plot style]
			\addplot [color=blue, mark=square]
			table {maqbool/data/vd16_pitts30k_to_tokyo247_maqbool_D_512.dat};
			\addplot [color=green, mark=square]
			table {maqbool/data/vd16_pitts30k_to_tokyo247_maqbool_R_512.dat};
			\addplot [color=black, mark=asterisk]
			table {maqbool/data/vd16_pitts30k_to_tokyo247_netvlad_512.dat};
			\legend{MAQBOOL$_{DT-50}$(ours), MAQBOOL$_{DT-100}$(ours),NetvLAD(V)+white}
			\end{axis}
			\end{tikzpicture}
		}
	}
	\captionsetup[subfigure]{width=.85\linewidth}
	\subfloat[Recall test on Tokyo 247 at 4096-D] 
	{\label{fig:pitts2tokyo-4096}
		\resizebox{.46\linewidth}{!}{
			\pgfplotsset{ymax=90, ymin= 64}
			\begin{tikzpicture}[trim axis left]%[width = 1in, height = 4in]
			\begin{axis}
			[curve plot style]
			
			\addplot [color=blue, mark=square]
			table {maqbool/data/vd16_pitts30k_to_tokyo247_maqbool_D_4096.dat};
			\addplot [color=green, mark=square]
			table {maqbool/data/vd16_pitts30k_to_tokyo247_maqbool_R_4096.dat};
			\addplot [color=black, mark=asterisk]
			table {maqbool/data/vd16_pitts30k_to_tokyo247_netvlad_4096.dat};
			\legend{MAQBOOL$_{DT-50}$(ours), MAQBOOL$_{DT-100}$(ours),NetvLAD(V)+white}
			\end{axis}
			\end{tikzpicture}
		}
	}
	\caption{MAQBOOL performance comparison with NetVLAD on Tokyo 247 dataset. Their retrieval performances are evaluated using the same VGG model, which is trained on the Pitts250k dataset.}
	\label{fig:pitts2tokyo}
\end{figure}



%black, red, green, blue, cyan, magenta, 
%\begin{figure*}[!t]
%	\centering
%	\begin{subfigure}[pt]{0.24\textwidth}
%		\resizebox{\columnwidth}{!}{
%			\pgfplotsset{ymin=85}
%			\begin{tikzpicture}%[width = 1in, height = 4in]
%				\begin{axis}
%					[curve plot style]
%					\addplot [color=blue, mark=square]
%					table {data/vd16_pitts30k_to_pitts30k_maqbool_D_4096_50.dat};
%					\addplot [color=green, mark=square]
%					table {data/vd16_pitts30k_to_pitts30k_maqbool_D_4096_100.dat};
%
%					%	\addplot [color=blue, mark=square] MAQBOOL$_D$(ours)
%					%	table {data/vd16_pitts30k_to_pitts30k_maqbool_D_4096.dat};
%					% RootSIFT+VLAD+white
%					%  \addplot [color=black, mark=square]
%					%  table {data/vd16_pitts30k_to_pitts30k_rootsift_4096.dat}; 
%					\addplot [color=black, mark=asterisk]
%					table {data/vd16_pitts30k_to_pitts30k_netvlad_4096.dat};
%					\legend{MAQBOOL$_{D-50}$(ours), MAQBOOL$_{D-100}$(ours), NetvLAD(V)+white}
%				\end{axis}
%			\end{tikzpicture}
%		}
%		\caption{Pitts250k at 4096-D}
%		\label{fig:4plots-pitts2pitts-4096}
%	\end{subfigure}
%	% \hspace{1mm}
%	\begin{subfigure}[pt]{0.24\textwidth}
%		\resizebox{\columnwidth}{!}{
%			\pgfplotsset{ymin=69}
%			\begin{tikzpicture}%[width = 1in, height = 4in]
%				\begin{axis}
%					[curve plot style]
%					\addplot [color=green, mark=square]
%					table {data/vd16_tokyoTM_to_tokyo247_maqbool_D_100_4096.dat};
%					%table {data/vd16_tokyoTM_to_tokyo247_maqbool_R_4096.dat};
%					\addplot [color=cyan, mark=square]
%					table {data/vd16_tokyoTM_to_tokyo247_maqbool_D_50_4096.dat};
%					%table {data/vd16_tokyoTM_to_tokyo247_maqbool_D_4096.dat};
%					% \addplot [color=cyan, mark=square] DenseVLAD
%					% table {data/vd16_tokyoTM_to_tokyo247_dencevlad_4096.dat};
%					\addplot [color=black, mark=asterisk]
%					table {data/vd16_tokyoTM_to_tokyo247_netvlad_4096.dat};
%
%					\legend{MAQBOOL$_{D-100}$ (ours),MAQBOOL$_{D-50}$ (ours), NetvLAD(V)+white}
%				\end{axis}
%			\end{tikzpicture}
%		}
%		\caption{Tokyo 247 at 4096-D}
%		\label{fig:4plots-tokyo2tokyo-4096}
%	\end{subfigure}
%	\begin{subfigure}[pt]{0.24\textwidth}
%		\resizebox{\columnwidth}{!}{
%			\pgfplotsset{ymin=80}
%			\begin{tikzpicture}%[width = 2in, height = 4in]
%				\begin{axis}
%					[curve plot style]
%					\addplot [color=blue, mark=square]
%					table {data/vd16_pitts30k_to_pitts30k_maqbool_D_512_50.dat};
%					\addplot [color=green, mark=square]
%					table {data/vd16_pitts30k_to_pitts30k_maqbool_D_512_100.dat};
%					\addplot [color=black, mark=asterisk]
%					table {data/vd16_pitts30k_to_pitts30k_netvlad_512.dat};
%					\legend{MAQBOOL$_{D-50}$(ours),MAQBOOL$_{D-100}$(ours), NetvLAD(V)+white}
%
%				\end{axis}
%			\end{tikzpicture}
%		}
%		\caption{Pitts250k at 512-D}
%		\label{fig:4plots-pitts2pitts-512}
%	\end{subfigure}
%	\begin{subfigure}[pt]{0.24\textwidth}
%		\resizebox{\columnwidth}{!}{
%			\pgfplotsset{ymin=55, ymax=90}
%			\begin{tikzpicture}%[width = 2in, height = 4in]
%				\begin{axis}
%					[curve plot style]
%					\addplot [color=green, mark=square]
%					table {data/vd16_tokyoTM_to_tokyo247_maqbool_R_512_D50.dat};
%					\addplot [color=blue, mark=square]
%					table {data/vd16_tokyoTM_to_tokyo247_maqbool_R_512_D100.dat};
%					\addplot [color=cyan, mark=square]
%					table {data/vd16_tokyoTM_to_tokyo247_maqbool_D_512.dat};
%					\addplot [color=black, mark=asterisk]
%					table {data/vd16_tokyoTM_to_tokyo247_netvlad_512.dat};
%					\addplot [color=magenta, mark=square]
%					table {data/vd16_tokyoTM_to_tokyo247__APA_512.dat};
%					\legend{MAQBOOL$_{D-50}$(ours), MAQBOOL$_{D-100}$(ours), MAQBOOL$_{D-simple}$(ours), NetvLAD(V)+white, APANet(V)}
%				\end{axis}
%			\end{tikzpicture}
%		}
%		\caption{Tokyo 247 at 512-D}
%		\label{fig:4plots-tokyo2tokyo-512}
%	\end{subfigure}
%	\caption{Recall @ 2-30 on Toyko 247 and Pittsburgh 250k datasets. (a) and (c) shows the performance of MAQBOOL compared to NetVLAD based on the model pre-trained on VGG Pittsburgh 250k. (c) and (d) show the performance based on the model pre-trained on VGG 247.}
%	\label{fig:4plots}
%\end{figure*}


\begin{figure*}[!t] 
	\centering
	\raggedright	
	\captionsetup[subfigure]{width=.9\linewidth}
	\subfloat[Pitts250k at 4096-D] 
	{	\label{fig:4plots-pitts2pitts-4096} 
		\resizebox{.22\linewidth}{!}{
			\begin{tikzpicture}[trim axis left]%[width = 1in, height = 4in]
			\begin{axis}
			[curve plot style]
			\addplot [color=blue, mark=square]
			table {maqbool/data/vd16_pitts30k_to_pitts30k_maqbool_D_4096_50.dat};
			\addplot [color=green, mark=square]
			table {maqbool/data/vd16_pitts30k_to_pitts30k_maqbool_D_4096_100.dat};
			
			%	\addplot [color=blue, mark=square] MAQBOOL$_D$(ours)
			%	table {data/vd16_pitts30k_to_pitts30k_maqbool_D_4096.dat};
			% RootSIFT+VLAD+white
			%  \addplot [color=black, mark=square]
			%  table {data/vd16_pitts30k_to_pitts30k_rootsift_4096.dat}; 
			\addplot [color=black, mark=asterisk]
			table {maqbool/data/vd16_pitts30k_to_pitts30k_netvlad_4096.dat};
			\legend{MAQBOOL$_{D-50}$(ours), MAQBOOL$_{D-100}$(ours), NetvLAD(V)+white}
			\end{axis}
			\end{tikzpicture}
		}
	}
	\captionsetup[subfigure]{width=.9\linewidth}
	\subfloat[Tokyo 247 at 4096-D] 
	{\label{fig:4plots-tokyo2tokyo-4096}
		\resizebox{.22\linewidth}{!}{
			\pgfplotsset{ymax=90, ymin= 64}
			\begin{tikzpicture}[trim axis left]%[width = 1in, height = 4in]
			\begin{axis}
			[curve plot style]
			\addplot [color=green, mark=square]
			table {maqbool/data/vd16_tokyoTM_to_tokyo247_maqbool_D_100_4096.dat};
			%table {data/vd16_tokyoTM_to_tokyo247_maqbool_R_4096.dat};
			\addplot [color=cyan, mark=square]
			table {maqbool/data/vd16_tokyoTM_to_tokyo247_maqbool_D_50_4096.dat};
			%table {data/vd16_tokyoTM_to_tokyo247_maqbool_D_4096.dat};
			% \addplot [color=cyan, mark=square] DenseVLAD
			% table {data/vd16_tokyoTM_to_tokyo247_dencevlad_4096.dat};
			\addplot [color=black, mark=asterisk]
			table {maqbool/data/vd16_tokyoTM_to_tokyo247_netvlad_4096.dat};
			
			\legend{MAQBOOL$_{D-100}$ (ours),MAQBOOL$_{D-50}$ (ours), NetvLAD(V)+white}
			\end{axis}
			\end{tikzpicture}
		}
	}
	\captionsetup[subfigure]{width=.9\linewidth}
	\subfloat[Pitts250k at 512-D] 
	{	\label{fig:4plots-pitts2pitts-512} 
		\resizebox{.22\linewidth}{!}{
			\begin{tikzpicture}[trim axis left]%[width = 1in, height = 4in]
			\begin{axis}
			[curve plot style]
			\addplot [color=blue, mark=square]
			table {maqbool/data/vd16_pitts30k_to_pitts30k_maqbool_D_512_50.dat};
			\addplot [color=green, mark=square]
			table {maqbool/data/vd16_pitts30k_to_pitts30k_maqbool_D_512_100.dat};
			\addplot [color=black, mark=asterisk]
			table {maqbool/data/vd16_pitts30k_to_pitts30k_netvlad_512.dat};
			\legend{MAQBOOL$_{D-50}$(ours),MAQBOOL$_{D-100}$(ours), NetvLAD(V)+white}
			
			\end{axis}
			\end{tikzpicture}
		}
	}
	\captionsetup[subfigure]{width=.9\linewidth}
	\subfloat[Tokyo 247 at 512-D] 
	{\label{fig:4plots-tokyo2tokyo-512}
		\resizebox{.22\linewidth}{!}{
			\pgfplotsset{ymax=90, ymin= 64}
			\begin{tikzpicture}[trim axis left]%[width = 1in, height = 4in]
			\begin{axis}
			[curve plot style]
			\addplot [color=green, mark=square]
			table {maqbool/data/vd16_tokyoTM_to_tokyo247_maqbool_R_512_D50.dat};
			\addplot [color=blue, mark=square]
			table {maqbool/data/vd16_tokyoTM_to_tokyo247_maqbool_R_512_D100.dat};
			\addplot [color=cyan, mark=square]
			table {maqbool/data/vd16_tokyoTM_to_tokyo247_maqbool_D_512.dat};
			\addplot [color=black, mark=asterisk]
			table {maqbool/data/vd16_tokyoTM_to_tokyo247_netvlad_512.dat};
			\addplot [color=magenta, mark=square]
			table {maqbool/data/vd16_tokyoTM_to_tokyo247__APA_512.dat};
			\legend{MAQBOOL$_{D-50}$(ours), MAQBOOL$_{D-100}$(ours), MAQBOOL$_{D-simple}$(ours), NetvLAD(V)+white, APANet(V)}
			\end{axis}
			\end{tikzpicture}
		}
	}
	\caption{Recall @ 2-30 on Toyko 247 and Pittsburgh 250k datasets. (a) and (c) shows the performance of MAQBOOL compared to NetVLAD based on the model pre-trained on VGG Pittsburgh 250k. (c) and (d) show the performance based on the model pre-trained on VGG 247.}
	\label{fig:4plots}
\end{figure*}




\begin{table*}[h]
	\caption{MAQBOOL performance comparison with APANet and NetvLAD}
	\centering
	\setlength{\tabcolsep}{1.4em} % for the horizontal padding
	\renewcommand{\arraystretch}{1.2}% for the vertical padding
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		\multirow{2}{*}{Method}                           & \multirow{2}{*}{Whitening} & \multicolumn{3}{c|}{Tokyo 24/7} & \multicolumn{3}{c|}{Pitts250k-test}                                                                                                               \\ \cline{3-8}
		
		&                            & \multicolumn{1}{c|}{Recall@1}   & \multicolumn{1}{c|}{Recall@5}       & \multicolumn{1}{c|}{Recall@10} & \multicolumn{1}{c|}{Recall@1} & \multicolumn{1}{c|}{Recall@5 } & Recall@10 \\
		\hline
		\hline
		%	\multirow{4}{*}{Mac}                              & W/o whitening              & 38.41                         & 52.7                           & 62.22 & 77.01                               & 88.73                           & 91.97                                     \\
		
		%	                                                  & PCA whitening              & 25.4                          & 40.63                          & 45.4  & 73.21                               & 86.03                           & 89.77                                    \\
		
		%	                                                  & PCA-pw                     & 35.56                         & 52.06                          & 60.95  & 79.19                               & 90.12                           & 93.09                                   \\
		
		%	                                                  & PCA-pw (a = 0.1)           & 38.73                         & 53.97                          & 62.54  & 78.25                               & 89.44                           & 92.26                                   \\
		%	\hline
		\multirow{2}{*}{Sum pooling}                      & PCA whitening              & 44.76                           & 60.95                               & 70.16                          & 74.13                         & 86.44                          & 90.18     \\
		
		& PCA-pw                     & 52.7                            & 67.3                                & 73.02                          & 75.63                         & 88.01                          & 91.75     \\
		\hline
		\multirow{2}{*}{NetVLAD \cite{arandjelovic2016netvlad} } & PCA whitening              & 60                              & 73.65                               & 79.05                          & 80.66                         & 90.88                          & 93.06     \\
		
		& PCA-pw                     & 58.73                           & 74.6                                & 80.32                          & 81.95                         & 91.65                          & 93.76     \\
		\hline
		\multirow{2}{*}{APANet \cite{zhu2018attention} }  & PCA whitening              & 61.9                            & 77.78                               & 80.95                          & 82.32                         & 90.92                          & 93.79     \\
		
		& PCA-pw                     & 66.98                           & 80.95                               & 83.81                          & 83.65                         & 92.56                          & 94.7      \\
		\hline
		\multirow{2}{*}{MAQBOOL (Ours)}                   & PCA whitening + DT-50       & 67.30                           & 83.18                               & 85.40                          & 80.07                         & 90.89                          & 93.31     \\
		& PCA whitening + DT-100      & 68.89                           & 82.54                               & 85.40                          & 82.65                         & 91.73                          & 96.18     \\
		
		
		
		\hline
	\end{tabular}
	\label{table-1}
\end{table*}


\begin{table*}[h]
	\caption{MAQBOOL performance comparison with APANet and NetvLAD}
	\centering
	\setlength{\tabcolsep}{1.4em} % for the horizontal padding
	\renewcommand{\arraystretch}{1.2}% for the vertical padding
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		\multirow{2}{*}{Method}                           & \multirow{2}{*}{Whitening} & \multicolumn{3}{c|}{Tokyo 24/7} & \multicolumn{3}{c|}{Pitts250k-test}                                                                                                               \\ \cline{3-8}
		
		&                            & \multicolumn{1}{c|}{Recall@1}   & \multicolumn{1}{c|}{Recall@5}       & \multicolumn{1}{c|}{Recall@10} & \multicolumn{1}{c|}{Recall@1} & \multicolumn{1}{c|}{Recall@5 } & Recall@10 \\
		\hline
		\hline
		%	\multirow{4}{*}{Mac}                              & W/o whitening              & 38.41                         & 52.7                           & 62.22 & 77.01                               & 88.73                           & 91.97                                     \\
		
		%	                                                  & PCA whitening              & 25.4                          & 40.63                          & 45.4  & 73.21                               & 86.03                           & 89.77                                    \\
		
		%	                                                  & PCA-pw                     & 35.56                         & 52.06                          & 60.95  & 79.19                               & 90.12                           & 93.09                                   \\
		
		%	                                                  & PCA-pw (a = 0.1)           & 38.73                         & 53.97                          & 62.54  & 78.25                               & 89.44                           & 92.26                                   \\
		%	\hline
		\multirow{2}{*}{Sum pooling}                      & PCA whitening              & 44.76                           & 60.95                               & 70.16                          & 74.13                         & 86.44                          & 90.18     \\
		
		& PCA-pw                     & 52.7                            & 67.3                                & 73.02                          & 75.63                         & 88.01                          & 91.75     \\
		\hline
		\multirow{2}{*}{NetVLAD \cite{arandjelovic2016netvlad} } & PCA whitening              & 60                              & 73.65                               & 79.05                          & 80.66                         & 90.88                          & 93.06     \\
		
		& PCA-pw                     & 58.73                           & 74.6                                & 80.32                          & 81.95                         & 91.65                          & 93.76     \\
		\hline
		\multirow{2}{*}{APANet \cite{zhu2018attention} }  & PCA whitening              & 61.9                            & 77.78                               & 80.95                          & 82.32                         & 90.92                          & 93.79     \\
		
		& PCA-pw                     & 66.98                           & 80.95                               & 83.81                          & 83.65                         & 92.56                          & 94.7      \\
		\hline
		\multirow{2}{*}{MAQBOOL (Ours)}                   & PCA whitening + DT-50       & 67.30                           & 83.18                               & 85.40                          & 80.07                         & 90.89                          & 93.31     \\
		& PCA whitening + DT-100      & 68.89                           & 82.54                               & 85.40                          & 82.65                         & 91.73                          & 96.18     \\
		
		
		
		\hline
	\end{tabular}
	\label{table-1}
\end{table*}

\begin{figure*}[!t] 
	\raggedright	
	\captionsetup[subfigure]{width=.93\linewidth}
	\subfloat[Recall test on Tokyo 247 dataset at features dimension D-512.] {\label{fig:results-thumb-tokyo2tokyo-512} 
		\includegraphics[width=.99\linewidth]{maqbool/data/tokyoTM-tokyo247-512.jpg}
	}
	\captionsetup[subfigure]{width=.93\linewidth}
	\subfloat[Recall test on Tokyo 247 dataset at features dimension D-4096.] {\label{fig:results-thumb-tokyo2tokyo-4096} 
		\includegraphics[width=.99\linewidth]{maqbool/data/tokyoTM-tokyo247-4096-2.jpg}
	}
	\captionsetup[subfigure]{width=.93\linewidth}
	\subfloat[Recall test on Pitts250k dataset at features dimension D-512.] {\label{fig:results-thumb-pitts2pitts-512} 
		\includegraphics[width=.99\linewidth]{maqbool/data/tokyoTM-pitts30-512.jpg}
	}
	\captionsetup[subfigure]{width=.93\linewidth}
	\subfloat[Recall test on Pitts250k dataset at features dimension D-4096.] {\label{fig:results-thumb-pitts2pitts-4096}
		\includegraphics[width=.99\linewidth]{maqbool/data/tokyoTM-pitts30-4096.jpg}
	}
	\caption{MAQBOOL vs. NetvLAD: (a) and (b) show the image retrieval compared to NetvLAD on Tokyo dataset with feature dimensions 512 and 4096. (c) and (d) show the recall on the Pittsburgh dataset with feature dimensions 512 and 4096.}
	\label{fig:results-thumb} 
\end{figure*}

\subsection{Prediction Model}

As mentioned in the previous section, we use a model at the PDL. We observe that the model also works better than NetVLAD if it is created using small datasets such as the Paris or Oxford building datasets. These datasets have 55 query images, so we choose ground truth data of the Tokyo Time Machine validation set to create the model. We apply $P_M^j =  f(\textbf{M}, d_{pre}, \textbf{C}_{qdb}, Y)$ and take the first 250 test data and create the model. However, we also create prediction models based on the  Oxford, Paris, and Holiday datasets, which show similar performance.

We choose the decision tree and Gaussian probability models for use in the PDT layer and discuss them as follows.\\
\subsubsection{Decision Tree (DT) model}
It is clear from the name that the DT model has a tree-like structure, and leaves are the outcomes of the structure. A binary decision tree separates the parent data into its subsets, called child nodes based on their probabilities.
In addition to this, it recursively divides the datasets to achieve the optimal hierarchy during the model training.

%Hum ny OptimizeHyperparameters ko use kia classification decision tree aur pruning b ki. Pruning is a ML technique which can reduce the size of a DT and prevents overtraining. Pruning is achieved by removing the nodes that have least effect on the overall classification performance [25].
We trained the model based on a '50' and '100' tree size for faster processing and to keep the simple structure. We choose bootstrap aggregation in the decision tree, which allows the tree to grow on an independently drawn bootstrap duplicate of the input. This reduces the variance and increases accuracy. We found that tree size '50' give better results than NetVLAD and comparable performance to APANeT. It also works better than the simple decision tree model.

\subsubsection{Gaussian Probability Model}
The Gaussian probability model is also a popular choice in regression studies. We observed that it has a similar performance with the decision tree of size '50'.


\subsection{Dimensional reductions}
In the SLAM system, incorporating high-dimensional features for loop closure detection is exhaustive for SLAM systems. It becomes challenging while using in multiagent SLAM system for place recognition. Therefore, researchers prefer to work with low-dimensional features for keeping the robustness of their systems. Fig. \ref{fig:pitts2tokyo} shows the MAQBOOL performance on the Tokyo 247 datasets with features of 512-D and 4096-D compared with the state-of-the-art NetVLAD. Both use the same model trained on the Pitts250k dataset and tested on the Tokyo 247 dataset. We achieved notable improvement at low-dimension (512-D) features-based recall comparable with 4096-D of NetVLAD.

\subsection{Testing on Pittsburgh and Tokyo 247 Datasets}
Fig. \ref{fig:4plots} shows the comparison of our proposed MAQBOOL strategy while testing on the Pittsburgh and Tokyo 247 datasets. Without any further training or introducing additional sensors or ground truth pieces of information to the system,  our framework outperforms the APANet PCA power whitening concept and the NetVLAD. In comparison to features dimension D-4096, we achieve huge improvement at feature dimension 512-D, as shown in Fig. \ref{fig:4plots-pitts2pitts-512} and \ref{fig:4plots-tokyo2tokyo-512}. $\alpha = 1$ is taken as default. We choose $\alpha =5$ for the Tokyo 247 dataset at 512-D. Top five recall results are shown in Fig. \ref{fig:results-thumb}. It is shown in Fig. \ref{fig:results-thumb-tokyo2tokyo-512} and \ref{fig:results-thumb-tokyo2tokyo-4096} that NetVLAD is failed to retrieve the nearest match with the query at the first five places. MAQBOOL successfully adjusted the distances of the retrieved images and re-rank the closest match to the first position. Similarly, Fig. \ref{fig:results-thumb-pitts2pitts-512} and \ref{fig:results-thumb-pitts2pitts-4096} show the robustness of our proposed system compared to NetVLAD at feature of 512-D and 4096-D respectively.

\subsection{Comparison with Power Whitening PCA}
While maintaining the same baseline of PCA whitening followed by NetVLAD, MAQBOOL outperforms NetVLAD as well as APANet, as shown in Table \ref{table-1}. APANet introduces an additional PCA power whitening concept on different block types and produces better performance than NetvLAD. By keeping the default PCA whitening, our simplest model delivers better results than the APANet. We observe that by increasing the tree size, there is a significant improvement in the accuracy. Moreover, for decision tree dimension D-100, MAQBOOL achieves good results compared to APANet on the Tokyo 247 dataset, as shown in Table \ref{table-1}. Material related to this work is available at \url{https://usmanmaqbool.github.io/why-so-deep}.

\newpage
\renewcommand*{\bibname}{\section{References}}
\bibliographystyle{ecta}
\bibliography{Thesis.bib}	

